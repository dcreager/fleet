.TH "flt_run" "3" "2014-01-01" "Fleet" "Fleet\ documentation"
.SH NAME
.PP
flt_run \[en] Scheduling tasks
.SH SYNOPSIS
.PP
\f[B]#include <fleet.h>\f[]
.PP
typedef void
.PD 0
.P
.PD
\f[B]flt_task_f\f[](struct flt *\f[I]flt\f[], void *\f[I]ud\f[], size_t
\f[I]i\f[]);
.PP
typedef void *
.PD 0
.P
.PD
\f[B]flt_migrate_f\f[](struct flt *\f[I]from\f[], struct flt
*\f[I]to\f[],
.PD 0
.P
.PD
\ \ \ \ \ \ \ \ \ \ \ \ \ \ void *\f[I]ud\f[], size_t \f[I]i\f[]);
.PP
void
.PD 0
.P
.PD
\f[B]flt_run\f[](struct flt *\f[I]flt\f[], flt_task_f *\f[I]func\f[],
void *\f[I]ud\f[], size_t \f[I]i\f[]);
.PP
void
.PD 0
.P
.PD
\f[B]flt_return_to\f[](struct flt *\f[I]flt\f[], flt_task
*\f[I]task\f[], void *\f[I]ud\f[], size_t \f[I]i\f[]);
.PP
void
.PD 0
.P
.PD
\f[B]flt_run_migratable\f[](struct flt *\f[I]flt\f[], flt_task_f
*\f[I]func\f[],
.PD 0
.P
.PD
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ void *\f[I]ud\f[], size_t
\f[I]i\f[],
.PD 0
.P
.PD
\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ flt_migrate_f *\f[I]migrate\f[]);
.SH DESCRIPTION
.PP
The \f[B]flt_run\f[] family of functions let you schedule a new task to
be run.
All of these functions take a \f[B]flt\f[](3) instance as their first
parameter.
However, there's no way to allocate your own \f[B]flt\f[](3) instance;
you only obtain one when a task function is executed.
That means that these functions can only be called from within an
already running task.
(Use \f[B]flt_fleet_run\f[](3) to start the initial \[lq]root\[rq] task
for a fleet.)
.PP
Each task is represented by a \[lq]task function\[rq], which is the
block of code that will execute when the fleet decides that it's time to
run the task, along with the \f[I]ud\f[] and \f[I]i\f[] parameters that
will be passed into the task function.
The task function's \f[I]ud\f[] and \f[I]i\f[] parameters are provided
when you schedule a task.
.PP
\f[B]flt_run\f[]() is the simplest function.
It gives you no control over when or where the new task is executed;
however, this gives the underlying fleet the most flexibility in
executing tasks in parallel.
You should only use the more complex variants if you really need the
extra constraints that they impose.
.PP
\f[B]flt_return_to\f[]() is a more efficient version of
\f[B]flt_run\f[]() that can only be used as the last statement of a
parent task.
(It can be anywhere in the parent task's function body, but must be used
in a \f[C]return\f[] statement to indicate that it's the last statement
the parent task will execute.) For example:
.IP
.nf
\f[C]
static\ flt_task\ \ child_task;
static\ flt_task\ \ parent_task;

static\ void
parent_task(struct\ flt\ *flt,\ void\ *ud,\ size_t\ i)
{
\ \ \ \ if\ (child_should_handle_work_instead)\ {
\ \ \ \ \ \ \ \ return\ flt_return_to(flt,\ child_task,\ ud,\ i);
\ \ \ \ }\ else\ {
\ \ \ \ \ \ \ \ /*\ do\ some\ work\ */
\ \ \ \ }
}
\f[]
.fi
.PP
On some platforms, this will automatically pass control to the child
task without passing through the fleet's scheduler first.
However, this is an optional optimization; like with \f[B]flt_run\f[](),
we don't make any guarantees about when or where the child task will be
executed.
.PP
Note that \f[B]flt_return_to\f[]() does not necessary return control to
the fleet scheduler before executing the next task.
You should be careful not to use this funtion too often, since one of
fleet's rules of thumbs is to not perform an unbounded amount of work
before returning to the scheduler.
.PP
\f[B]flt_run_migratable\f[]() schedules a task along with a
\f[I]migration function\f[].
This lets you update the \f[I]ud\f[] parameter that will be passed into
the task function if the fleet scheduler moves the task to some other
execution context.
This allows to make optimizing assumptions about the data that you pass
into your task, while still having a fallback mechanism to transfer data
between context threads safely.
.PP
For all of these functions, you must ensure that any \f[I]ud\f[] input
parameters remain valid until the task has a chance to run.
Effectively, this means that the responsibility for freeing the inputs
belongs to the new task, or to some subtask that it creates.
.PP
Note that all of these functions are allowed to return before the newly
scheduled child task starts to execute.
There isn't any way for the parent task to wait for newly scheduled
child tasks to start or complete.
If you need to know when the child task completes, you must use an
\f[B]flt_scounter\f[](3).
.SS Data sharing
.PP
We don't place any restrictions on which particular values you pass in
for the \f[I]ud\f[] parameter for your tasks.
However, for the most part, we also don't make any guarantees about when
or where a particular task is going to run.
That means that if you pass a pointer to a shared data instance to two
tasks, it's entirely possible for those two tasks to execute
simultaneously, in separate native OS threads.
.PP
If the tasks only \f[B]read\f[] from the shared data, then everything is
fine.
The shared data is never changed or updated, and so it doesn't matter
when or where each task reads the data.
(The only wrinkle is that you must ensure that the data isn't freed
until all of the tasks that use the data have finished.)
.PP
If one or more of the tasks need to \f[B]write\f[] to the shared data,
the story is different.
You must ensure that it's not possible for there to be any read/write or
write/write conflicts.
.PP
One way to do this is to use \f[B]flt_return_to\f[]() to schedule a new
task.
This function must be the last statement the parent task executes, so
it's safe for the parent to pass its \f[I]ud\f[] parameter (or some
portion of it) on to the new child task: anything the parent does to the
data must happen \f[I]before\f[] the \f[B]flt_return_to\f[]() call, and
everything the child does to the data must happen \f[I]after\f[].
So this data sharing pattern is safe.
